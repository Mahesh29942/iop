{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95076f2",
   "metadata": {},
   "source": [
    "# understanding neural network in simple steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "480acc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469301f",
   "metadata": {},
   "source": [
    "# Loading Diabetes Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60744d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset for\n",
    "data = pd.read_csv(\"C:/Users/mahes/OneDrive/Desktop/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2146672d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewring data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69acae5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Outcome'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "data['Outcome'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabc009",
   "metadata": {},
   "source": [
    "# Preparing Data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad1c2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "predictors = data.iloc[:,0:8]\n",
    "response = data.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d4593ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8) (614,)\n",
      "(154, 8) (154,)\n"
     ]
    }
   ],
   "source": [
    "#create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, \n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd125bd3",
   "metadata": {},
   "source": [
    "# Trainig the neural network model         \n",
    "there are two ways to build Keras models: Sequential and functional\n",
    "\n",
    "the sequential API allows you to create models layer-by-layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3558d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    " #define the keras model - layer by layer\n",
    "kerasmodel = Sequential() #initializing model - dense for fully connected layer\n",
    "kerasmodel.add(Dense(12, input_dim=8, activation='relu'))\n",
    "kerasmodel.add(Dense(8, activation='relu'))\n",
    "kerasmodel.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c25b979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kerasmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eabe8680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "62/62 [==============================] - 1s 3ms/step - loss: 5.7530 - accuracy: 0.6221\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 2.1792 - accuracy: 0.6173\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.9400 - accuracy: 0.6254\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7998 - accuracy: 0.6498\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7634 - accuracy: 0.6515\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7937 - accuracy: 0.6270\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7072 - accuracy: 0.6564\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6711 - accuracy: 0.6694\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.7273 - accuracy: 0.6564\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.6759\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.6775\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.6645\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.6694\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6889\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6759\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6938\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.6987\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.7117\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6808\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.6954\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5919 - accuracy: 0.7036\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6808\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.6987\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.6808\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.6694\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.6889\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7052\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6824\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.6873\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.7003\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7182\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5882 - accuracy: 0.7150\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.7003\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5943 - accuracy: 0.7117\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5834 - accuracy: 0.6938\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.7085\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7052\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.7036\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.7101\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5699 - accuracy: 0.6987\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.6987\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5702 - accuracy: 0.7394\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6084 - accuracy: 0.6987\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5672 - accuracy: 0.7085\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5828 - accuracy: 0.7182\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7329\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.6824\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5977 - accuracy: 0.7085\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.7134\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7296\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7166\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5901 - accuracy: 0.7068\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7199\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.7020\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7410\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7150\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.7231\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.7248\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.7248\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.7264\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5842 - accuracy: 0.7036\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7231\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7410\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7345\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5333 - accuracy: 0.7378\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7573\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7459\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.7231\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7427\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7313\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7427\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7427\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.7036\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7508\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7541\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7557\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7150\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7280\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7280\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.7231\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7557\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7394\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5466 - accuracy: 0.7199\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7378\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.7410\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5624 - accuracy: 0.7182\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.7296\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.7443\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7443\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7459\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7476\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7476\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5532 - accuracy: 0.7313\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7524\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7410\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7410\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5169 - accuracy: 0.7427\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7443\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7313\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7752\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7410\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5023 - accuracy: 0.7590\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7476\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7476\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5419 - accuracy: 0.7264\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.7134\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7638\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7443\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5253 - accuracy: 0.7378\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7524\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7231\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7638\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7557\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7329\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7248\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7443\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.7541\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.7557\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.7557\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7622\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.7655\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7573\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7671\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7736\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.7590\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7443\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7590\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7687\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.7345\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.7638\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7655\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7573\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7524\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.7541\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7410\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7590\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.7704\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7655\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.7524\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7508\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7524\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7655\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.7769\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7590\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7687\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7362\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.7606\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7182\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7573\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fd6b349e50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kerasmodel.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb4c9924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7769\n",
      "Train Accuracy: 77.69\n"
     ]
    }
   ],
   "source": [
    "# train accuracy \n",
    "_, accuracy = kerasmodel.evaluate(X_train, y_train)\n",
    "print('Train Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f27d25e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahes\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ed68086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7467532467532467\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e74ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
